#######################################################################
# This is a snake file of sentieon call snp pipeline.
#   Examples:
#       snakemake --configfile default.yaml
#       snakemake --configfile default.yaml --config fasta='reference.fasta fastq_folder='fatsq'
#       snakemake --configfile default.yaml -j 24 --cluster "qsub -V -cwd -j y -q all.q -pe mpi {threads}"
#                                                  
#
######################################################################
import os
import glob
import os.path as op

release_dir = config['release_dir']
fasta = config['fasta']
fastq_folder = config['fastq_folder']
workdirs = op.join(os.getcwd(), config['workdir'])
reads = config['reads']
ext = config['ext']
nt = config['nt']
platform = config['platform']


samples = list(map(op.basename, [i.replace(ext, "").replace(reads[0], "") 
            for i in glob.glob('{}/*{}{}'.format(fastq_folder, reads[0], ext))]))

rule all:
    input:
        expand("{workdirs}/output-jc.vcf.gz", workdirs=workdirs)

rule faidx:
    input:
        fasta 
    output:
        fasta + ".fai"
    log:
        "run_faidx.log"
    shell:
        "samtools faidx {intput}"

rule bwtindex:
    input:
        fasta = config['fasta']
    output:
        fasta + '.bwt'
    log:
        "run_bwt.log"
    shell:
        "bwa index -a bwtsw {input}"
    
rule mapping:
    input: 
        fasta = config['fasta'],
        read1 = fastq_folder +"/{sample}" + reads[0] + ext,
        read2 = fastq_folder +"/{sample}" + reads[1] + ext,
        fai = fasta + '.fai',
        bwt = fasta + '.bwt'
    output: 
        "{workdirs}/{sample}/sort.bam"
    params:
        workdir = workdirs
    threads:nt
    log:
        "{workdirs}/{sample}/run_mapping.log"
    shell: 
        """
        exec >> {log} 2>&1;
        mkdir -p {workdirs}/{wildcards.sample} && \
        ( {release_dir}/bin/bwa mem -M -R "@RG\tID:{wildcards.sample} \
       \tSM:{wildcards.sample}\tPL:{platform}" -t {threads} \
        -K 10000000 \
        {input.fasta} {input.read1} \
        {input.read2} || echo -n "error" ) | \
           {release_dir}/bin/sentieon util sort \
       -r {input.fasta} -o {output} \
       -t {nt} --sam2bam -i - 
       """

rule metrics:
    input:
        "{workdirs}/{sample}/sort.bam"
    output:
        '{workdirs}/{sample}/mq_metrics.txt',
        '{workdirs}/{sample}/qd_metrics.txt',
        '{workdirs}/{sample}/gc_summary.txt',
        '{workdirs}/{sample}/gc_metrics.txt',
        '{workdirs}/{sample}/aln_metrics.txt',
        '{workdirs}/{sample}/is_metrics.txt'
    threads: nt
    log:
        "{workdirs}/{sample}/run_metrics.log"
    shell:
        """
        exec >> {log} 2>&1;
        {release_dir}/bin/sentieon driver \
            -r {fasta} -t {threads} -i {input} \
                --algo MeanQualityByCycle {output[0]} \
                    --algo QualDistribution {output[1]} \
                        --algo GCBias --summary {output[2]} {output[3]}\
                            --algo AlignmentStat --adapter_seq '' {output[4]} \
                                --algo InsertSizeMetricAlgo {output[5]} 2>>{log}\
       
        """
rule plot_metrics:
    input:
        '{workdirs}/{sample}/mq_metrics.txt',
        '{workdirs}/{sample}/qd_metrics.txt',
        '{workdirs}/{sample}/gc_summary.txt',
        '{workdirs}/{sample}/gc_metrics.txt',
        '{workdirs}/{sample}/aln_metrics.txt',
        '{workdirs}/{sample}/is_metrics.txt'
    output:
        '{workdirs}/{sample}/metrics-report.pdf'
    log:
        "{workdirs}/{sample}/run_plot_metrics.log"
    shell:
        """
        exec >> {log} 2>&1
        {release_dir}/bin/sentieon plot metrics \
            -o {output} \
                gc={input[3]} \
                    qd={input[1]} \
                        mq={input[0]} \
                            isize={input[5]}
        """
rule rmdup:
    input:
        '{workdirs}/{sample}/metrics-report.pdf',
        "{workdirs}/{sample}/sort.bam"
    output:
        '{workdirs}/{sample}/dedup_metrics.txt',
        '{workdirs}/{sample}/deduped.bam'
    log:
        "{workdirs}/{sample}/run_rmdup.log"
    threads: nt
    shell:
        """
        exec >> {log} 2>&1
        {release_dir}/bin/sentieon driver  \
            -t {threads} -i {input[1]} \
                --algo LocusCollector \
                    --fun score_info {workdirs}/{wildcards.sample}/score.txt;
        {release_dir}/bin/sentieon driver  -t {threads} \
        -i {input[1]} --algo Dedup --rmdup --score_info {workdirs}/{wildcards.sample}/score.txt \
            --metrics {output[0]} {output[1]}
        """

rule uniqe:
    input:
        '{workdirs}/{sample}/deduped.bam'
    output:
        "{workdirs}/{sample}/unique.bam"
    threads: nt
    log: 
         "{workdirs}/{sample}/run_uniqe.log" 
    shell:
        """
        exec >> {log} 2>&1; 
        sh {release_dir}/bin/non_unique_mapping_uniform.sh \
            {threads} {fasta} {input} {workdirs}/{wildcards.sample}/read_names.txt;  
        {release_dir}/bin/sentieon driver -t {threads} \
            -i {input} \
                --algo Dedup --rmdup \
                --dup_read_name {workdirs}/{wildcards.sample}/read_names.txt \
                    {output}
    """

rule realigner:
    input:
        '{workdirs}/{sample}/unique.bam'
    output:
        '{workdirs}/{sample}/realigned.bam'
    threads: nt
    log:
        "{workdirs}/{sample}/run_religner.log" 
    shell:
        """
        exec >> {log} 2>&1; 
        {release_dir}/bin/sentieon driver -r {fasta}  \
            -t {threads} -i {input} --algo Realigner {output}
        """

rule recal:
    input:
        '{workdirs}/{sample}/realigned.bam'
    output:
        "{workdirs}/{sample}/recal.csv", 
        "{workdirs}/{sample}/recal_data.table",
        "{workdirs}/{sample}/recal_data.table.post",
        "{workdirs}/{sample}/recal_plots.pdf"
    log:
        "{workdirs}/{sample}/run_recal.log" 
    threads: nt
    shell:
        """
        exec >> {log} 2>&1; 
         {release_dir}/bin/sentieon driver -r {fasta} \
             -t {threads} -i {input} --algo QualCal {output[1]};
        {release_dir}/bin/sentieon driver -r {fasta} -t {threads} -i {input} \
            -q {output[1]} --algo QualCal {output[2]};
        {release_dir}/bin/sentieon driver -t {threads} \
            --algo QualCal --plot --before {output[1]} \
                --after {output[2]} {output[0]};
        {release_dir}/bin/sentieon plot bqsr -o {output[3]} {output[0]}
        """

rule hc:
    input:
        '{workdirs}/{sample}/realigned.bam',
        '{workdirs}/{sample}/recal_data.table'
    output:
        "{workdirs}/{sample}/output-hc.g.vcf.gz"
    log:
        "{workdirs}/{sample}/run_hc.log" 
    threads: nt
    shell:
        """
        exec >> {log} 2>&1; 
        {release_dir}/bin/sentieon driver \
            -r {fasta} -t {threads} -i {input[0]} \
                -q {input[1]} --algo Haplotyper \
                    --emit_conf=10 --call_conf=30 \
                        --emit_mode gvcf {output}
        """
def addv(s):
    res = []
    for i in s:
        res.append('-v {}'.format(i))
    return " ".join(res)


rule joint:
    input:
        expand("{workdir}/{sample}/output-hc.g.vcf.gz", workdir=workdirs, sample=samples)
    output:
        "{workdirs}/output-jc.vcf.gz"
    log:
        "{workdirs}/run.log" 
    params:
        gvcf = addv(expand("{workdir}/{sample}/output-hc.g.vcf.gz", workdir=workdirs, sample=samples))
        
    shell:
        """
        exec >> {log} 2>&1; 
        {release_dir}/bin/sentieon driver -r {fasta} \
            --algo GVCFtyper {params.gvcf} {output}
        """
